---
title: "Predicting salaries of WNBA players"
author: Caban
date: '`r Sys.Date()`'
output:
  html_document:
    code_folding: hide
    number_sections: yes
    theme: lumen
    toc: yes
    toc_depth: 3
    toc_float: yes
urlcolor: blue
---


```{r setup, include=FALSE}

# Set knitr options
knitr::opts_chunk$set(
  echo = T, 
  fig.width=8, 
  # fig.height=4, 
  warning = F, 
  dpi = 300,
  message = F,
  comment = NA
  )





if(!require('pacman')) {install.packages('pacman')}

# Load all libraries
pacman::p_load(DT, readxl,leaps, rstatix, bestglm, glmnet, leaps, car, tidyverse, pROC, caret, tree, rpart, randomForest, rpart.plot)


```






```{r}

# create functions and general ggplot vectors to streamline code and make it more reproducible




# Function to control the table output
kable2 <- function(x) {
  datatable(x)
     }


# Plot color palette 
colors <- c(
  "#6C946F",
  "#FFD35A",
  "#FFA823",
  "#DC0083"
)


# Histogram
plot_hist <- list(
  geom_histogram(aes(y= after_stat(density)), fill=colors[1], color=colors[4]),
  geom_density(color=colors[2], linewidth=1),
  theme_light(),
  theme(plot.title = element_text(hjust = 0.5))
)


# Line plot
plot_line2 <- list(
  geom_line(color = colors[1]),
  scale_color_manual(values = c(colors[1], colors[2])),
  guides(color = "none"),
  theme_light(),
  theme(
    plot.title = element_text(hjust = 0.5)
    )
)


```



# Methodology


## Datasets

The WNBA players' stats were scraped form:
https://www.basketball-reference.com/


Salaries
https://www.spotrac.com/wnba/rankings/

CPI:
https://stats.oecd.org




## Variables


Variables imported as part of the players' stats

| Abbreviation | Description                            |
|--------------|----------------------------------------|
| Pos          | Position                               |
| G            | Games                                  |
| MP           | Minutes Played                         |
| GS           | Games Started                          |
| FG           | Field Goals                            |
| FGA          | Field Goal Attempts                    |
| FG%          | Field Goal Percentage                  |
| 3P           | 3-Point Field Goals                    |
| 3PA          | 3-Point Field Goal Attempts            |
| 3P%          | 3-Point Field Goal Percentage          |
| 2P           | 2-Point Field Goals                    |
| 2PA          | 2-point Field Goal Attempts            |
| 2P%          | 2-Point Field Goal Percentage          |
| FT           | Free Throws                            |
| FTA          | Free Throw Attempts                    |
| FT%          | Free Throw Percentage                  |
| ORB          | Offensive Rebounds                     |
| TRB          | Total Rebounds                         |
| AST          | Assists                                |
| STL          | Steals                                 |
| BLK          | Blocks                                 |
| TOV          | Turnovers                              |
| PF           | Personal Fouls                         |
| PTS          | Points                                 |



# Data Import and Cleaning


## Salaries

```{r}
# Import salary dataset
salaries <- read_csv("WNBA - salaries.csv")

salaries %>% 
  glimpse()
```



```{r}

salaries %>% 
  is.na() %>% 
  colSums()

```



```{r}
duplicates <- salaries %>% 
  duplicated() %>% 
  sum()




```

There were `r duplicates` duplicates in the salary dataset.

```{r}
salaries[duplicated(salaries),]
```

The only duplicate concers Sylvia Fowles.
According to spotrac (url: https://www.spotrac.com/wnba/player/_/id/29907/sylvia-fowles#:~:text=Sylvia%20Fowles%20signed%20a%203%20year%20%2C%20%24333%2C540%20contract%20with%20the,average%20annual%20salary%20of%20%24111%2C180.) she extended her contract averaging 115k dollars a year. 
As such this duplicate seems to be a random error and is safe to be removed.


```{r}
# Remove duplicates
salaries <- salaries %>%
  rename(year = Year) %>%
  unique()


# Format salaries to double
salaries$Salary

salaries <- salaries %>% 
  mutate(
    Salary = str_replace_all(Salary, pattern = "\\$|,", "") %>% as.double()
  )


  

```







### Adjusting salaries for inflation

Our dependent variable is salary. As we have data from several years, we would like to adjust the values for inflation. This way they will reflect a more "*true*" value across years.


```{r}
salaries %>%
  count(year) %>% 
  kable2()
```


We have salary data for years `r min(salaries$year)` - `r max(salaries$year)`.


```{r}
cpi <- read_csv("CPI.csv")
cpi2 <- cpi %>%
  filter(
    Measure == "Index",
    Country == "United States",
    Subject == "CPI: 01-12 - All items",
    Time %in% c(as.character(2018:2022), str_c("Q", 1:3, "-2023"))
    ) %>%
  select(Time, Value) %>%
  mutate(Time = str_replace(Time, "Q[1-3]-", "")) %>%
  group_by(Time) %>%
  summarise(
    CPI = mean(Value) # We take the mean of the quaterly 2023 data
  ) %>%
  mutate(year = as.double(Time)) %>%
  select(-Time)
```

Here is the formula for the inflation adjustment factor:

$$ Inflation\; Adjustment\; Factor = \frac{CPI \; in\; Base\; Year}{CPI \; in\;
Current\; Year} $$

We choose 2023 as the base year. 
Therefore, we will adjust the salaries from previous years (2018 to 2022) to reflect their value in 2023 dollars.


```{r}
CPI_base <- cpi2 %>% 
  filter(year == 2023) %>% 
  pull(CPI)
  

salaries <- salaries %>%
  left_join(cpi2) %>%
  mutate(
    iaf = CPI_base / CPI,
    salary_adj = Salary * iaf
  ) %>% 
  select(-c(CPI, iaf))

# Extract a single player that played in most years
player_example <- salaries %>% 
  count(Player) %>% 
  arrange(desc(n)) %>% 
  slice(1) %>% 
  pull(Player)

salaries %>% 
  select(Player, year, Salary, salary_adj) %>% 
  filter(Player == player_example) %>% 
  kable2()

```

As expected, the salaries for all years expect for the current (base) year increased, as to reflect their value in terms of the value of 2023 dollar.



## WNBA stats


```{r}

# Import codebook
codebook <- read_excel("codebook.xlsx") %>% 
  select(-1)

# List player stats datasets for all years
stats_files <- list.files("players stats")

# Vector for import
stats_import <- str_c("players stats/", stats_files)

# Extract year
wnba_year <- str_extract(stats_files, pattern = "[0-9]+") %>% 
  as.double()

# Import all files
stats_imported <- stats_import %>% 
  map(read_excel)

# Check compatibility
stats_imported %>% 
  map(names) %>% 
  reduce(setdiff)
```

There are no differences in names of the datasets when compared one after another


```{r}

stats_imported %>% 
  map_dbl(length) %>% 
  unique()
```

All datasets have the same number of variables


```{r}
# Combine all WNBA stats datasets into one
wnba_stats <- stats_imported %>% 
  map2(
    wnba_year,
    ~mutate(.x, year = .y)
  ) %>% 
  reduce(add_row)

```


```{r}

glimpse(wnba_stats)

```


```{r}
wnba_stats %>% 
  duplicated() %>% 
  sum()

```


```{r}

wnba_stats %>% 
  select(where(is.character)) %>% 
  select(-Player) %>% 
  map(unique)


```


### Correcting vector type

```{r}

wnba_stats <- wnba_stats %>% 
  mutate(
    across(ends_with("%"), ~as.double(.))
  )

```


### Summary stats

```{r}

wnba_stats %>% 
  get_summary_stats()

```


### Correcting duplicates 

#### Duplicated variables

```{r}

# Correcting duplicate variables
duplicated_vars <- wnba_stats %>% 
  as.list.data.frame() %>% 
  duplicated() 


wnba_stats[, duplicated_vars]




  

```

Two variables are duplicated. 


```{r}


# Remove duplicates
wnba_stats <- wnba_stats[, !duplicated_vars]


```



#### Duplicated observations

```{r}

wnba_stats %>% 
  duplicated() %>% 
  sum()

```



```{r}

wnba_stats %>% 
  select(Player, year) %>% 
  duplicated() %>% 
  sum()

```



```{r}
player_duplicates <- wnba_stats %>% 
  count(Player, year) %>% 
  filter(n >= 2) %>% 
  arrange(desc(n))

player_duplicates %>% 
  kable2()

```

We have `r nrow(player_duplicates)` cases in which a given player in a given year had more than one set of stats.


```{r}

wnba_stats %>% 
  count(Player, Team, year) %>% 
  filter(n >= 2)




```


This can be explained by some of the players changing their team at least once in a given year.

This raises a methodological question. 
Given that the salaries dataset shows salaries for a given year, in order to combine those with wnba stats each player should have one summarized set of stats for a given year.

A possible solution is to sum stats over a given year for those players who played in more than one team during this year. 

The only limitation would be the position variable, as it is a categorical variable. 

```{r}

wnba_stats %>% 
  count(Player, Pos, year) %>% 
  filter(n >= 2) %>% 
  count(Player, year) %>% 
  filter(n >= 2)

```

However, each player that changed team in a given year nevertheless remained playing on the same position.



```{r}

wnba_summarized <- wnba_stats %>% 
  group_by(Player, year) %>% 
  select(-ends_with("%")) %>% # Exclude percentage variables
  summarise(
    across(where(is.double), ~sum(.))
  ) %>% 
  ungroup()

wnba_position <- wnba_stats %>% 
  group_by(Player, year) %>%
  select(Pos) %>% 
  slice(1) %>% 
  ungroup()
  

wnba_stats2 <- wnba_position %>% 
  left_join(wnba_summarized)

```

```{r}
# create vector for filtering over pairs of successes and attemps
pct_filter <- wnba_stats %>% 
  select(ends_with("%") )%>% 
  names() %>% 
  str_replace("%", "") 

# Vector to loop over
wnba_pct <- list()

# Obtain percentages after data modification
for (var in pct_filter) {
  
  # Select a pair of attemps and successes
  vars <- wnba_stats2 %>% 
    select(starts_with(var)) %>% 
    select(sort(names(.)))
  
  # Calculate percentage of successes over attemps
  pct <- vars[, 1] / vars[, 2]
  
  wnba_pct[[var]] <- pct
  
  
}

wnba_pct <- wnba_pct %>% 
  reduce(add_column) %>% 
  rename_with(~str_c(., "%"))


wnba_stats3 <- wnba_stats2 %>% 
  add_column(wnba_pct) 

wnba_stats3 %>% 
  select(starts_with(pct_filter[1]))

```



### Missing data


```{r}

wnba_missing <- wnba_stats3 %>% 
  is.na() %>% 
  colSums() %>% 
  sort(decreasing = T) %>% 
  keep(~. != 0)

wnba_missing %>% 
  enframe(name = "variable", value = "missing_sum")
  

```

Missing data were observed only for the variables measuring percentage of successes in a given performance category.

Let's inspect observations in terms of the absolute success and overall attempts separately
for each category only for the missing data.


```{r}
## Inspect all missing observations ##



# Empty list
wnba_NAs <- list()

# Obtain separate datasets with missing variables for each set of variables
for (i in seq_along(pct_filter)) {
  
  wnba_NAs[[i]] <- wnba_stats3 %>% 
    select(starts_with(pct_filter[i])) %>% 
    filter(if_any(everything(), ~is.na(.))) %>% 
    select(sort(names(.))) %>% 
    set_names(c("Absolute successes", "Pct successes", "Total attemps")) %>% 
    mutate(category = pct_filter[[i]])
  
}


wnba_NAs %>% 
  map(unique) %>% 
  reduce(add_row) %>% 
  select(category, everything())
```

As we can see, missing data for percentage of success occurred only in situations when there were zero total attempts. 
This makes sense, because you can obtain a proportion out of nothing.


```{r}
pct_filter %>% 
  map(select, .data = wnba_stats3)

wnba_chunks <- pct_filter %>% 
  map(~select(wnba_stats3, starts_with(.))) %>% 
  map(drop_na)


wnba_chunks %>% 
  map(cor_test)
```


```{r}
wnba_chunks %>% 
  map(plot)


```

There are strong linear associations between successes and attempts for each category of player's performance, above 0.9 high.
In case of linear models, it would be necessary to remove either of the two for each pair, in order to avoid collinearity. 

Interestingly, the relationship between the percentage of successful attempts and the absolute values of the sucessess and attempts is not linear. 
The majority of observations had a visible middle with 2P and FG being located mostly between 20% and 70% of successful attempts and
3P between 15% and 50%, showing in the respective areas also a relatively large dispersion of absolute attempts and successes.
Players below or above the respective ranges were noticeably similar to one another in terms of absolute attempts and successes having values close to zero.
This implies that having just a few attempts makes the player's percentage of successes a less objective performance measure, as one or two shots can decide whether a player has 0 or 100% success rate.

The exception is for FT (free throws) for which majority of the observations had a success rate above 60% which was also associated with a higher variance on both absolute measures - attempts and successes. 
Given that a free throw is unhindered and always from the same position, it would on average easier to succeed in a given attempt. 


```{r}

wnba_chunks %>% 
  map(
    ~filter(., .[[names(.)[[3]]]] <= 0.2 | .[[names(.)[[3]]]] >= 0.70)
    ) %>% 
  map(
    get_summary_stats
  )

```


```{r}
wnba_chunks %>% 
  map(
    ~filter(., .[[names(.)[[2]]]] > 50)
    ) %>% 
  map(plot)
```





```{r}

wnba_chunks %>% 
  map(select, 1:2) %>% 
  map(cor_test)

```

This poses a methodological trade-off dilemma.
On one hand, the percentage index by showing the proportion of success to all attempts, seems to capture better the effectiveness of a player. 
On the other, it seems to at the same time favor and neglect those players who had just several attempts in total.

It also raises the question what to do with `NA` values. 



```{r}

wnba_stats3

```





## Combine datasets



```{r}
# Move salaries one year back
salaries_back <- salaries %>% 
  mutate(year = year - 1)
```

Assuming a logical perspective, we would expect that salary would be a consequence of player's prior overall performance.
Therefore, before combining datasets, we should move salaries one year back to associate it with stats from the year prior to the year of salary.


```{r}
# Combine datasets
wnba_combined <- salaries_back %>% 
  left_join(wnba_stats3) 


wnba_combined %>% 
  is.na() %>% 
  colSums() %>% 
  sort(decreasing = T) %>% 
  enframe(name = "variable", value = "Number of missing values") %>% 
  kable2()

```



```{r}

# Select only complete observations
wnba_complete <- wnba_combined %>% 
  filter(!if_all(-names(salaries), is.na)) %>% 
  select(-c(Salary, Player)) %>% # Remove the unadjusted salary and player name
  select( salary_adj, everything()) %>%
  rename(
    Games = G...4,
    Minutes = MP...5
  ) %>% 
  mutate(
    year = factor(year),
    Pos = factor(Pos)
    )


# Adjust variable names to make them comptabile with all modelling functions



```



```{r}

wnba_complete %>% 
  is.na() %>% 
  colSums() %>% 
  keep(~. != 0) %>% 
  enframe(name = "variable", value = "Number of missing values") %>% 
  kable2()

```


We are still left with a substantial number of observations that have zero attempts in at least one of the four performance categories.

# EDA

## Summary stats

```{r}

wnba_complete %>% 
  get_summary_stats()

```


## Distribution of the variables

```{r}

pivoted_everything <- wnba_complete %>% 
  pivot_longer(-c(Pos, year)) 

pivoted_everything %>% 
  ggplot(aes(value)) +
  geom_histogram() +
  facet_wrap(~name, scales = "free")


```






```{r}

pivoted_everything %>% 
  ggplot(aes(value)) +
  geom_boxplot() +
  facet_wrap(~name, scales = "free")


```




```{r}

wnba_complete %>% 
  freq_table(Pos) %>% 
  ggplot(aes(Pos, prop)) +
  geom_bar(stat = "identity")


```


## Salary over other variables


### Salary throughout years


```{r}

wnba_complete %>% 
  ggplot(aes(year, salary_adj)) +
  geom_boxplot()


```

### Salary based on the position



```{r}

wnba_complete %>% 
  ggplot(aes(Pos, salary_adj)) +
  geom_boxplot()


```



### Salary based on stats


```{r}

pivoted_Onsalary <- wnba_complete %>% 
  select(where(is.double)) %>% 
  pivot_longer(-salary_adj)


pivoted_Onsalary %>% 
  ggplot(aes(value, salary_adj)) +
  geom_point(alpha = 1/3) +
  geom_smooth(se = F) +
  facet_wrap(~name, scales = "free", ncol = 5)

```





```{r}

pivoted_Onsalary %>% 
  ggplot(aes(value, salary_adj)) +
  geom_hex() +
  geom_smooth(se = F) +
  facet_wrap(~name, scales = "free", ncol = 5)

```

None of the continuous predictors has a linear relationship with the salary variable.
Based on that it is to predict that variants of tree models will perform better.


### Correlations between predictors


```{r}

cor_predictors <- wnba_complete %>% 
  select(-c(salary_adj, year, Pos)) %>% 
  cor_test(method = "pearson") %>% 
  filter(cor != 1) %>% 
  arrange(desc(abs(cor))) %>% 
  mutate(across(where(is.numeric), ~round(., 3))) %>% 
  select(-c(statistic, method))

cor_predictors %>% 
  kable2()

```

There is a substantial number of highly correlated predictors.
First and foremost, we see almost perfect correlations between successes and attempts for each performance category pair.
Similarly, there are very strong to near perfect correlations between number of points and some of the performance metrics, specifically, 2-points field goals, field goals, and free throws.




```{r}
cor_predictors %>% 
  filter(var1 %in% pct_filter, var2 %in% pct_filter  )



```



```{r}

cor_predictors %>% 
  filter(abs(cor) >= 0.8) %>% 
  count(var1, name = "High correlations count")  %>% 
  arrange(desc(`High correlations count`)) %>% 
  kable2()

```

Field goals, field goals attempts and points were the predictors with the highest count of strong correlations, posing highest risk for multicollinearity.



# Modelling



## Features modification


```{r}
# Rename variables to make  them comptabile with all modelling functions
wnba_complete <-  wnba_complete %>% 
  rename_with(~str_replace_all(., "2", "Two_")) %>% 
  rename_with(~str_replace_all(., "3", "Three_")) %>% 
  rename_with(~str_replace_all(., "%", "_pct"))
```


```{r}

# Create two versions of datasets
model_full <- wnba_complete %>% 
  mutate(across(ends_with("pct"), ~replace_na(., 0))) 

model_reduced <- wnba_complete %>% 
  select(-ends_with("pct"))

model_datasets <- tibble(
  dataset = c("full", "reduced"),
  whole = list(model_full, model_reduced)
)


```






## Data separation



```{r}

set.seed(123)

# Set up k-indexing
indices <- sample(1:2, nrow(wnba_complete), prob = c(0.8, 0.2), replace = T)

model_datasets <- model_datasets %>% 
  mutate(
    train = map(whole, ~.[indices == 1,]),
    test = map(whole, ~.[indices == 2,]),
    x_train = map(train, ~model.matrix(salary_adj ~ ., .x )[, -1]),
    x_train_df = map(x_train, as_tibble),
    y_train = map(train, ~.x$salary_adj)
  )





```


## Linear models 



```{r}

# Extract regsubsets function
regsubset_own <- function(data, nvmax, method = "forward") {
  regsubsets(
    data = data, 
    nvmax = nvmax, 
    x = salary_adj ~ ., 
    method = method
    )
}


# Function for fitting a new linear model based on regsubset
subset_lm <- function(regsubset, id, data) {
  
  # Extract coefficients
  coefs <- regsubset %>% 
    coef(id = id) %>% 
    names() %>% 
    keep(~. != "(Intercept)")
  
  # Prepare formula
  mod_formula <- str_c("salary_adj ~ ", str_c(coefs, collapse = " + ")) %>% 
    as.formula()
  
  # Fit model
  fit_lm <- lm(mod_formula, data = data)
  
  return(fit_lm)
  
}


regsubsets_models <- model_datasets %>% 
  select(dataset, train, x_train_df, y_train) %>% 
  mutate(
    id = map(train, ~1:(ncol(.) - 1)),
    predictors_total = map_dbl(train, ncol),
    fit_forward = map2(train, predictors_total, regsubset_own,method = "forward")
    ) 
  

# Wymyślić cross-validation function

regsubsets_models %>% 
  unnest(id) %>% 
  mutate(
    lm = pmap(list(fit_forward, id, x_train_df), subset_lm)
  )

regsubsets_models$fit_forward[[1]] %>% 
  coef(id = 3) %>% 
  names() %>% 
  keep(~. != "(Intercept)")
  



```





